{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0dbcab2220adf41",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.1 Decision Theory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1\n",
    "\n",
    "(a) \n",
    "Assume that we managed to represent objects from a two-class classification problem by a single feature. \n",
    "We know that the objects from class ω1 have a 2.2 Gaussian distribution with $μ_{1}$ = 0 and $σ_{1}^2$ = 1/2, and the objects from class ω2 have\n",
    "a Gaussian distribution with $μ_{2}$ = 1 and $σ_{2}^2$ = 1/2. Derive the position of the decision boundary when both class priors are equal. (Note that we are now assuming that we know the distributions exactly, so effectively we’re making the Bayes classifier.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
